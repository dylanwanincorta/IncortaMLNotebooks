{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f7fc75",
   "metadata": {},
   "source": [
    "## Account Receivables Aging Prediction Model\n",
    "\n",
    "This notebook is for maintaining the prediction model for predicting the AR Aging.  The concept is based on a public available paper <a href=\"https://drive.google.com/drive/u/0/folders/1g6Q2rIODGYGDLqx3NblZlGFuk1cjjb6k\">_Using Predictive Analysis to Improve Invoice-to-Cash Collection_</a>.\n",
    "We will use the customer, invoice, and historical payment information from Oracle E-Business Suite as the input and predict the payment aging for the <b>future unpaid invoices </b>\n",
    "\n",
    "The Spark ML libary is used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98750f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml.feature import *\n",
    "import pyspark.sql.functions as F\n",
    "import sys\n",
    "\n",
    "# Incorta Data API that will enable accessing incorta data and save the data back to Incorta with the format\n",
    "from incorta_data_apis import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b675d",
   "metadata": {},
   "source": [
    "<h2>Connect to Incorta</h2>\n",
    "This step is for connecting to Incorta.  We need to provide:\n",
    "\n",
    "- Incorta Tenant:  <b>ebsmldemo</b> This links to the EBS ML Demo env\n",
    "- User to access incorta:  <b>admin</b>\n",
    "- Generated Key for authenticating the user\n",
    "\n",
    "Incorta connects to Spark cluster for running ML model and pipeple. <br>\n",
    "The notebook env will have the access to Spark binary as the client, which will access to Spark master, which can be remote on the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3851349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Tenant:  ebsmldemo\n",
      "Username:  admin\n",
      "API Key:  ····································\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using spark.home: /home/incorta/IncortaAnalytics/IncortaNode/spark\n",
      "Spark Context is available as 'sc'\n",
      "Spark Session is available as 'spark'\n"
     ]
    }
   ],
   "source": [
    "incorta=IncortaAPI('/home/incorta/IncortaAnalytics/IncortaNode/bin/data_apis/python/data-api.conf')\n",
    "\n",
    "#API Key\n",
    "#4c7fe62a-fca7-4a5c-a93e-6b4faab6d131"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8cec24",
   "metadata": {},
   "source": [
    "<h2>Read data from Incorta</h2>\n",
    "Incorta provides different ways to get the data from Incorta into Spark dataframe and panda dataframe:\n",
    "\n",
    "| API         | Input                |Output            |Example   |Description   |\n",
    "|-------------|----------------------|------------------|----------|--------------|\n",
    "| read        | \\<Schema\\>.\\<table\\> |Spark Dataframe   |<b>df = incorta.read(\"Sales.Sales\")</b>|Read from a table or a materialized view|\n",
    "| sql         | SQL statment         |Spark Dataframe   |df = incorta.sql(\"\"\"<br>SELECT * <br>FROM Sales.Sales<br>\"\"\")|Read from multiple tables or materailized views |\n",
    "| sql_pg      | SQL statement        |Spark Dataframe   |df = incorta.sql_pg(\"\"\"<br>SELECT * <br>FROM BusinesView.MyView<br>\"\"\")|Write a Incorta PostgreSQL statement.  This SQL is full compatible with Incorta SQL interface (SQLi), whcih can access business view and formula columns |\n",
    "| read_panda  | \\<Schema\\>.\\<table\\> |Panda Dataframe   |df = incorta.read_pandas(\"Sales.Sales\")|The result will be directly converted to panda dataframe|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1f13291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = incorta.read(\"AR_ML_Demo.AR_DATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a68165",
   "metadata": {},
   "source": [
    "### Source Data\n",
    "\n",
    "Customer payment history from EBS with the customer information like Ship to Account , Bill to Account, Location, Payment Terms, and the customer invoices, collector, amount, etc.\n",
    "\n",
    "The <b>Late Bucket</b> is the label we would like to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "457b4894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Billing_Period: date (nullable = true)\n",
      " |-- Payment_Status: string (nullable = true)\n",
      " |-- Payment_Class: string (nullable = true)\n",
      " |-- Invoice_Number: string (nullable = true)\n",
      " |-- Sales_Channel_Code___Ship_To_Account: string (nullable = true)\n",
      " |-- Sales_Channel_Code___Bill_To_Account: string (nullable = true)\n",
      " |-- Customer: string (nullable = true)\n",
      " |-- Country_Name___Bill_To_Location: string (nullable = true)\n",
      " |-- City___Bill_To_Location: string (nullable = true)\n",
      " |-- Country_Name___Ship_To_Location: string (nullable = true)\n",
      " |-- City___Ship_To_Location: string (nullable = true)\n",
      " |-- Collector: string (nullable = true)\n",
      " |-- Operating_Unit: string (nullable = true)\n",
      " |-- Transaction_Type: string (nullable = true)\n",
      " |-- Transaction_Subtype: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Payment_Terms: string (nullable = true)\n",
      " |-- As_Of_Date: date (nullable = true)\n",
      " |-- Invoice_Created_Date: date (nullable = true)\n",
      " |-- Credit_Limit: long (nullable = true)\n",
      " |-- Due_Date: date (nullable = true)\n",
      " |-- Days_Overdue: long (nullable = true)\n",
      " |-- Aging_Bucket: string (nullable = true)\n",
      " |-- Aging_Bucket_2: string (nullable = true)\n",
      " |-- Late_Bucket: string (nullable = true)\n",
      " |-- Very_Overdue: long (nullable = true)\n",
      " |-- Amount_Due_Original: double (nullable = true)\n",
      " |-- Amount_Due_Remaining: double (nullable = true)\n",
      " |-- Write_Off_Amount: double (nullable = true)\n",
      " |-- Filename: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0390471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the empty label column\n",
    "featureLabelColumn = df[\"Late_Bucket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30ce642a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Cannot resolve column name \"Invoice_Number\" among (invoice, featureLabel, amount, term, agingBucket, unit, subtype, daysOverdue, customer, status, type, collector, countryBill, cityBill, accountBill, countryShip, cityShip, accountShip, writeOffAmount, veryOverdue, paymentClass, create, due, pay);'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/IncortaAnalytics/IncortaNode/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IncortaAnalytics/IncortaNode/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1444.apply.\n: org.apache.spark.sql.AnalysisException: Cannot resolve column name \"Invoice_Number\" among (invoice, featureLabel, amount, term, agingBucket, unit, subtype, daysOverdue, customer, status, type, collector, countryBill, cityBill, accountBill, countryShip, cityShip, accountShip, writeOffAmount, veryOverdue, paymentClass, create, due, pay);\n\tat org.apache.spark.sql.Dataset.$anonfun$resolve$1(Dataset.scala:223)\n\tat scala.Option.getOrElse(Option.scala:138)\n\tat org.apache.spark.sql.Dataset.resolve(Dataset.scala:223)\n\tat org.apache.spark.sql.Dataset.col(Dataset.scala:1268)\n\tat org.apache.spark.sql.Dataset.apply(Dataset.scala:1235)\n\tat sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b584eccf39db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m df = df.select(\n\u001b[0;32m----> 2\u001b[0;31m       \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Invoice_Number\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invoice\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m       \u001b[0mfeatureLabelColumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"featureLabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0;31m#df[\"Tickets\"].alias(\"tickets\"),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;31m#df[\"Avg_Close_Days\"].alias(\"AvgCloseDays\"),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IncortaAnalytics/IncortaNode/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \"\"\"\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m             \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IncortaAnalytics/IncortaNode/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IncortaAnalytics/IncortaNode/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Cannot resolve column name \"Invoice_Number\" among (invoice, featureLabel, amount, term, agingBucket, unit, subtype, daysOverdue, customer, status, type, collector, countryBill, cityBill, accountBill, countryShip, cityShip, accountShip, writeOffAmount, veryOverdue, paymentClass, create, due, pay);'"
     ]
    }
   ],
   "source": [
    "df = df.select(\n",
    "      df[\"Invoice_Number\"].alias(\"invoice\"),     \n",
    "      featureLabelColumn.alias(\"featureLabel\"),  \n",
    "      #df[\"Tickets\"].alias(\"tickets\"),\n",
    "      #df[\"Avg_Close_Days\"].alias(\"AvgCloseDays\"),\n",
    "      df[\"Amount_Due_Original\"].alias(\"amount\"), \n",
    "      df[\"Payment_Terms\"].alias(\"term\"),         \n",
    "      df[\"Aging_Bucket\"].alias(\"agingBucket\"),       \n",
    "      df[\"Operating_Unit\"].alias(\"unit\"),\n",
    "      df[\"Transaction_Subtype\"].alias(\"subtype\"),\n",
    "      df[\"Days_Overdue\"].alias(\"daysOverdue\"),       \n",
    "      df[\"Customer\"].alias(\"customer\"),\n",
    "      df[\"Status\"].alias(\"status\"),   \n",
    "      df[\"Transaction_Type\"].alias(\"type\"),\n",
    "      df[\"Collector\"].alias(\"collector\"),\n",
    "      df[\"Country_Name___Bill_To_Location\"].alias(\"countryBill\"),\n",
    "      df[\"City___Bill_To_Location\"].alias(\"cityBill\"),\n",
    "      df[\"Sales_Channel_Code___Bill_To_Account\"].alias(\"accountBill\"),\n",
    "      df[\"Country_Name___Ship_To_Location\"].alias(\"countryShip\"),\n",
    "      df[\"City___Ship_To_Location\"].alias(\"cityShip\"),\n",
    "      df[\"Sales_Channel_Code___Ship_To_Account\"].alias(\"accountShip\"),\n",
    "      df[\"Write_Off_Amount\"].alias(\"writeOffAmount\"),\n",
    "      df[\"Very_Overdue\"].alias(\"veryOverdue\"),\n",
    "      df[\"Payment_Class\"].alias(\"paymentClass\"),\n",
    "      to_date(df[\"Invoice_Created_Date\"], 'MM/dd/yy').alias('create'),    # Created Date\n",
    "      to_date(df[\"Due_Date\"], 'MM/dd/yy').alias('due'),      # Due Date\n",
    "      ) \\\n",
    "    .withColumn(\"pay\", F.expr(\"date_add(due, daysOverdue)\")) \\\n",
    "    #.where(\"customer IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c0efb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+---------+------+------------+-----------------+--------------+-----------+--------------+-----------+----+---------+-----------+----------+-----------+-----------+--------+-----------+--------------+-----------+------------+----------+----------+----------+\n",
      "|     invoice|  featureLabel|   amount|  term| agingBucket|             unit|       subtype|daysOverdue|      customer|     status|type|collector|countryBill|  cityBill|accountBill|countryShip|cityShip|accountShip|writeOffAmount|veryOverdue|paymentClass|    create|       due|       pay|\n",
      "+------------+--------------+---------+------+------------+-----------------+--------------+-----------+--------------+-----------+----+---------+-----------+----------+-----------+-----------+--------+-----------+--------------+-----------+------------+----------+----------+----------+\n",
      "|      131496|> 60 days Late|  1182.83|30 NET|        210+|Vision Industries|    WF_Invoice|       4345|A. C. Networks|Outstanding| INV|     null|       null|Manchester| COMMERCIAL|       null|    null| COMMERCIAL|           0.0|          1|         INV|2009-04-14|2009-05-14|2021-04-06|\n",
      "|rct-10087604|      Not Late|451833.73|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2018-11-19|2018-12-19|2018-12-19|\n",
      "|    10091098|      Not Late|482368.32|30 NET|Paid In Time|Vision Operations|Inv-Hdwre-East|          0|A. C. Networks|       Paid| INV|     null|       null|     Provo| COMMERCIAL|       null|    null| COMMERCIAL|           0.0|          0|         INV|2019-02-15|2019-03-17|2019-03-17|\n",
      "|rct-10090959|      Not Late|191437.99|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2019-01-18|2019-02-17|2019-02-17|\n",
      "|rct-10047598|      Not Late|261961.69|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2019-05-07|2019-06-06|2019-06-06|\n",
      "|rct-10114698|      Not Late|302722.81|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2018-12-16|2019-01-15|2019-01-15|\n",
      "|rct-10061599|      Not Late|179434.74|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2018-03-05|2018-04-04|2018-04-04|\n",
      "|    10087604|      Not Late|451833.73|30 NET|Paid In Time|Vision Operations|Inv-Hdwre-East|          0|A. C. Networks|       Paid| INV|     null|       null|     Provo| COMMERCIAL|       null|    null| COMMERCIAL|           0.0|          0|         INV|2018-12-13|2019-01-12|2019-01-12|\n",
      "|rct-10091682|      Not Late|216419.29|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2019-01-30|2019-03-01|2019-03-01|\n",
      "|rct-10114697|      Not Late|302722.81|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2018-12-16|2019-01-15|2019-01-15|\n",
      "|    10049973|      Not Late|482368.32|30 NET|Paid In Time|Vision Operations|Inv-Hdwre-East|          0|A. C. Networks|       Paid| INV|     null|       null|     Provo| COMMERCIAL|       null|    null| COMMERCIAL|           0.0|          0|         INV|2018-04-02|2018-05-02|2018-05-02|\n",
      "|rct-10071833|      Not Late| 19106.99|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2018-04-29|2018-05-29|2018-05-29|\n",
      "|    10090099|      Not Late|179434.74|30 NET|Paid In Time|Vision Operations|Inv-Hdwre-East|          0|A. C. Networks|       Paid| INV|     null|       null|     Provo| COMMERCIAL|       null|    null| COMMERCIAL|           0.0|          0|         INV|2019-01-30|2019-03-01|2019-03-01|\n",
      "|rct-10091098|      Not Late|482368.32|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2019-01-18|2019-02-17|2019-02-17|\n",
      "|rct-10114722|      Not Late|302722.81|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2018-12-16|2019-01-15|2019-01-15|\n",
      "|    10090098|      Not Late|216419.29|30 NET|Paid In Time|Vision Operations|Inv-Hdwre-East|          0|A. C. Networks|       Paid| INV|     null|       null|     Provo| COMMERCIAL|       null|    null| COMMERCIAL|           0.0|          0|         INV|2019-01-30|2019-03-01|2019-03-01|\n",
      "|rct-10047592|      Not Late|451833.73|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2019-05-07|2019-06-06|2019-06-06|\n",
      "|    10061686|      Not Late|451833.73|30 NET|Paid In Time|Vision Operations|Inv-Hdwre-East|          0|A. C. Networks|       Paid| INV|     null|       null|     Provo| COMMERCIAL|       null|    null| COMMERCIAL|           0.0|          0|         INV|2018-04-03|2018-05-03|2018-05-03|\n",
      "|rct-10048226|      Not Late|191437.99|30 NET|Paid In Time|Vision Operations|         OTHER|          0|A. C. Networks|       Paid| N/A|     null|       null|     Provo| COMMERCIAL|       null|    null|       null|           0.0|          0|         PMT|2018-01-20|2018-02-19|2018-02-19|\n",
      "|    10061600|      Not Late| 19106.99|30 NET|Paid In Time|Vision Operations|Inv-Hdwre-East|          0|A. C. Networks|       Paid| INV|     null|       null|     Provo| COMMERCIAL|       null|    null| COMMERCIAL|           0.0|          0|         INV|2018-04-03|2018-05-03|2018-05-03|\n",
      "+------------+--------------+---------+------+------------+-----------------+--------------+-----------+--------------+-----------+----+---------+-----------+----------+-----------+-----------+--------+-----------+--------------+-----------+------------+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f86cb742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|           term|\n",
      "+---------------+\n",
      "|   2/10, Net 30|\n",
      "|         Net 60|\n",
      "| End Next Month|\n",
      "|            N30|\n",
      "|      IMMEDIATE|\n",
      "|         30 NET|\n",
      "|       30/60/90|\n",
      "|         Net 15|\n",
      "|2/10, N30 (PPD)|\n",
      "|         Net 90|\n",
      "|   Upon Receipt|\n",
      "|        Pay Now|\n",
      "|2% 10, Due 10th|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"term\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b84e750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------+------+\n",
      "|CASE WHEN (cityShip IS NULL) THEN Null ELSE Not Null END| count|\n",
      "+--------------------------------------------------------+------+\n",
      "|                                                    Null|241494|\n",
      "+--------------------------------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(F.when(F.col(\"cityShip\").isNull(), F.lit(\"Null\")).otherwise(F.lit(\"Not Null\"))).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2828f09d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Summary of Features</h2>\n",
    "\n",
    "| No | Feature                                                      | Description     |\n",
    "|----|:-------------------------------------------------------------|-----------------|\n",
    "| 1  |                                                              |                 |\n",
    "| 2  |                                                              |                 |\n",
    "| 3  |                                                              |                 |\n",
    "| 4  | Number of total paid invoices                                |                 |\n",
    "| 5  | Number of invoices that were paid late                       |                 |\n",
    "| 6  | Ratio of paid invoices that were late                        |                 |\n",
    "| 7  | Sum of the base amount of total paid invoices                |                 |\n",
    "| 8  | Sum of the base amount of invoices that were paid late       |                 |\n",
    "| 9  | Ratio of sum of paid base amount that were late              |                 |\n",
    "| 10 | Average days late of paid invoices being late                |                 |\n",
    "| 11 | Number of total outstanding invoice                          |                 |\n",
    "| 12 | Number of total outstanding invoice                          |                 |\n",
    "| 13 | Ratio of outstanding invoices that were late                 |                 |\n",
    "| 14 | Sum of the base amount of total outstanding invoices         |                 |\n",
    "| 15 | Sum of the base amount of outstanding invoices that were late|                 |\n",
    "| 16 | Ratio of sum of outstanding base amount that were late       |                 |\n",
    "| 17 | Average days late of outstanding invoices being late         |                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823c9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe8706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = F.lit(0)\n",
    "CREATE = \"CREATE\"\n",
    "DUE = \"DUE\"\n",
    "PAY = \"PAY\"\n",
    "\n",
    "create_df = df.withColumnRenamed(\"create\", \"date\").drop(\"due\").drop(\"pay\").withColumn(\"op\", F.lit(CREATE))\n",
    "due_df = df.withColumnRenamed(\"due\", \"date\").drop(\"create\").drop(\"pay\").withColumn(\"op\", F.lit(DUE))\n",
    "pay_df = df.withColumnRenamed(\"pay\", \"date\").drop(\"create\").drop(\"due\").withColumn(\"op\", F.lit(PAY))\n",
    "\n",
    "history_df = create_df.union(due_df).union(pay_df)\n",
    "history_window = Window.orderBy(F.unix_timestamp(\"date\")).partitionBy(\"customer\").rangeBetween(-sys.maxsize, -1)\n",
    "# history_df.createOrReplaceTempView(\"history_df\")\n",
    "\n",
    "\n",
    "#Feature Engineering \n",
    "due_condition = (history_df[\"op\"] == DUE)\n",
    "paid_condition = (history_df[\"op\"] == PAY)\n",
    "paid_late_condition = (paid_condition) & (history_df[\"featureLabel\"] != \"Not Late\")\n",
    "paid_ontime_condition = (paid_condition) & (history_df[\"featureLabel\"] == \"Not Late\")\n",
    "# Feature 4. Number of total paid invoices\n",
    "history_df = history_df.withColumn(\"paidCount\",\n",
    "                F.coalesce(F.sum(F.when(paid_condition, 1).otherwise(0)).over(history_window), zero))\n",
    "\n",
    "# Feature 5. Number of invoices that were paid late\n",
    "history_df = history_df.withColumn(\"paidLateCount\",\n",
    "                F.coalesce(F.sum(F.when(paid_late_condition, 1).otherwise(0)).over(history_window), zero))\n",
    "\n",
    "# Feature 6. Ratio of paid invoices that were late\n",
    "history_df = history_df.withColumn(\"paidCountRatio\",\n",
    "                F.coalesce(history_df[\"paidLateCount\"] / history_df[\"paidCount\"], zero))\n",
    "\n",
    "# Feature 7. Sum of the base amount of total paid invoices\n",
    "history_df = history_df.withColumn(\"paidAmount\",\n",
    "                F.coalesce(F.sum(F.when(paid_condition, history_df[\"amount\"]).otherwise(0)).over(history_window), zero))\n",
    "\n",
    "# Feature 8. Sum of the base amount of invoices that were paid late\n",
    "history_df = history_df.withColumn(\"paidLateAmount\", \n",
    "                F.coalesce(F.sum(F.when(paid_late_condition, history_df[\"amount\"]).otherwise(0)).over(history_window), zero))\n",
    "\n",
    "# Feature 9. Ratio of sum of paid base amount that were late\n",
    "history_df = history_df.withColumn(\"paidAmountRatio\", \n",
    "                F.coalesce(history_df[\"paidLateAmount\"] / history_df[\"paidAmount\"], zero))\n",
    "\n",
    "# Feature 10. Average days late of paid invoices being late\n",
    "history_df = history_df.withColumn(\"lateAvgDays\",\n",
    "                F.coalesce(\n",
    "                    F.sum(F.when(paid_late_condition, history_df[\"daysOverdue\"]).otherwise(0)).over(history_window) / \n",
    "                    F.sum(F.when(paid_late_condition, 1).otherwise(0)).over(history_window),\n",
    "                    zero\n",
    "                ))\n",
    "\n",
    "# Feature 11. Number of total outstanding invoice\n",
    "history_df = history_df.withColumn(\"outstandingCount\",\n",
    "                F.coalesce(\n",
    "                    F.sum(F.when(due_condition, 1).otherwise(0)).over(history_window) - \n",
    "                    F.sum(F.when(paid_condition, 1).otherwise(0)).over(history_window), \n",
    "                    zero\n",
    "                ))\n",
    "\n",
    "# Feature 12. Number of total outstanding invoice\n",
    "history_df = history_df.withColumn(\"outstandingLateCount\",\n",
    "                F.coalesce(\n",
    "                    F.sum(F.when(due_condition, 1).otherwise(0)).over(history_window) - \n",
    "                    F.sum(F.when(paid_condition, 1).otherwise(0)).over(history_window) -\n",
    "                    F.sum(F.when(paid_ontime_condition, 1).otherwise(0)).over(history_window), \n",
    "                    zero\n",
    "                ))\n",
    "history_df = history_df.withColumn(\"outstandingLateCount\", F.when(history_df[\"outstandingLateCount\"] > 0, history_df[\"outstandingLateCount\"]).otherwise(0))\n",
    "\n",
    "# Feature 13. Ratio of outstanding invoices that were late\n",
    "history_df = history_df.withColumn(\"outstandingRatio\", \n",
    "                F.coalesce(history_df[\"outstandingLateCount\"] / history_df[\"outstandingCount\"], zero))\n",
    "\n",
    "\n",
    "# Feature 14. Sum of the base amount of total outstanding invoices\n",
    "history_df = history_df.withColumn(\"outstandingAmount\",\n",
    "                F.coalesce(\n",
    "                    F.sum(F.when(due_condition, history_df[\"amount\"]).otherwise(0)).over(history_window) - \n",
    "                    F.sum(F.when(paid_condition, history_df[\"amount\"]).otherwise(0)).over(history_window), \n",
    "                    zero\n",
    "                ))\n",
    "\n",
    "# Feature 15. Sum of the base amount of outstanding invoices that were late\n",
    "history_df = history_df.withColumn(\"outstandingLateAmount\",\n",
    "                F.coalesce(\n",
    "                    F.sum(F.when(due_condition, history_df[\"amount\"]).otherwise(0)).over(history_window) - \n",
    "                    F.sum(F.when(paid_condition, history_df[\"amount\"]).otherwise(0)).over(history_window) -\n",
    "                    F.sum(F.when(paid_ontime_condition, history_df[\"amount\"]).otherwise(0)).over(history_window), \n",
    "                    zero\n",
    "                ))\n",
    "history_df = history_df.withColumn(\"outstandingLateAmount\", F.when(history_df[\"outstandingLateAmount\"] > 0, history_df[\"outstandingLateAmount\"]).otherwise(0))\n",
    "\n",
    "# Feature 16. Ratio of sum of outstanding base amount that were late\n",
    "history_df = history_df.withColumn(\"outstandingAmountRatio\", \n",
    "                F.coalesce(history_df[\"outstandingLateAmount\"] / history_df[\"outstandingAmount\"], zero))\n",
    "\n",
    "# Feature 17. Average days late of outstanding invoices being late.\n",
    "history_df = history_df.withColumn(\"outstandingLateAvgDays\",\n",
    "                F.coalesce(\n",
    "                    F.sum(F.when(due_condition, history_df[\"daysOverdue\"]).otherwise(0)).over(history_window) - \n",
    "                    F.sum(F.when(paid_condition, history_df[\"daysOverdue\"]).otherwise(0)).over(history_window) -\n",
    "                    F.sum(F.when(paid_ontime_condition, history_df[\"daysOverdue\"]).otherwise(0)).over(history_window),\n",
    "                    zero\n",
    "                ))\n",
    "history_df = history_df.withColumn(\"outstandingLateAvgDays\", \n",
    "                F.coalesce(history_df[\"outstandingLateAvgDays\"] / history_df[\"outstandingLateCount\"], zero))\n",
    "\n",
    "history_df = history_df.withColumn(\"writeOffTotalAmount\",\n",
    "                F.coalesce(F.sum(F.when(paid_condition, history_df[\"writeOffAmount\"]).otherwise(0)).over(history_window), zero))\n",
    "\n",
    "history_df = history_df.withColumn(\"veryOverdueCount\",\n",
    "                F.coalesce(F.sum(F.when(paid_condition, history_df[\"veryOverdue\"]).otherwise(0)).over(history_window), zero))\n",
    "\n",
    "history_df = history_df.where(\"op = 'CREATE'\").drop(\"op\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36156429",
   "metadata": {},
   "source": [
    "<h2>Building the Indexes</h2>\n",
    "\n",
    "The follow step will take a while\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fce7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### history_df.createOrReplaceTempView(\"history_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ae6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalFeatures = [\"term\",\n",
    "                       \"unit\",\n",
    "                       \"type\",\n",
    "                       \"subtype\",\n",
    "                       \"customer\",\n",
    "                       \"collector\",\n",
    "                       \"countryBill\",\n",
    "                       \"cityBill\",\n",
    "                       \"accountBill\",\n",
    "                       \"countryShip\",\n",
    "                       \"cityShip\",\n",
    "                       \"accountShip\",\n",
    "                       \"paymentClass\",\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05d63b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad0b506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[invoice: string, featureLabel: string, amount: double, term: string, agingBucket: string, unit: string, subtype: string, daysOverdue: bigint, customer: string, status: string, type: string, collector: string, countryBill: string, cityBill: string, accountBill: string, countryShip: string, cityShip: string, accountShip: string, writeOffAmount: double, veryOverdue: bigint, paymentClass: string, date: date, paidCount: bigint, paidLateCount: bigint, paidCountRatio: double, paidAmount: double, paidLateAmount: double, paidAmountRatio: double, lateAvgDays: double, outstandingCount: bigint, outstandingLateCount: bigint, outstandingRatio: double, outstandingAmount: double, outstandingLateAmount: double, outstandingAmountRatio: double, outstandingLateAvgDays: double, writeOffTotalAmount: double, veryOverdueCount: bigint, label: double, term_index: double, unit_index: double, type_index: double, subtype_index: double, customer_index: double, collector_index: double, countryBill_index: double, cityBill_index: double, accountBill_index: double, countryShip_index: double, cityShip_index: double, accountShip_index: double, paymentClass_index: double]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_bucket_indexer = StringIndexer(inputCol=\"featureLabel\", outputCol=\"label\").fit(indexed)\n",
    "indexed = late_bucket_indexer.transform(indexed)\n",
    "categoricalFeaturesCardinality = {}\n",
    "feature_index = 0\n",
    "indexed_features = []\n",
    "indexers = []\n",
    "for feature in categoricalFeatures:\n",
    "    indexed_feature = feature + \"_index\"\n",
    "    indexed_features.append(indexed_feature)    \n",
    "    indexer = StringIndexer(inputCol = feature, outputCol = indexed_feature).setHandleInvalid(\"keep\").fit(indexed)\n",
    "    indexed = indexer.transform(indexed)\n",
    "    feature_index = feature_index + 1\n",
    "indexed.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf7d8de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "\n",
    "customer_indexer = StringIndexer(inputCol=\"customer\", outputCol=\"customer_label\").fit(indexed)\n",
    "## customer_indexer.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e970aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = 0\n",
    "max_cardinality = 120\n",
    "for indexer in indexers:\n",
    "    cardinality = len(indexer.labels)\n",
    "    if(cardinality > max_cardinality):\n",
    "        max_cardinality = cardinality\n",
    "    categoricalFeaturesCardinality[feature_index] = cardinality\n",
    "    feature_index = feature_index + 1\n",
    "\n",
    "features = indexed_features + [\n",
    "               \"amount\", \n",
    "               \"paidCount\", \n",
    "               \"paidLateCount\", \n",
    "               \"paidCountRatio\", \n",
    "               \"paidAmount\", \n",
    "               \"paidLateAmount\", \n",
    "               \"paidAmountRatio\", \n",
    "               \"lateAvgDays\",\n",
    "               \"outstandingCount\",\n",
    "               \"outstandingLateCount\",\n",
    "               \"outstandingRatio\",\n",
    "               \"outstandingAmount\",\n",
    "               \"outstandingLateAmount\",\n",
    "               \"outstandingAmountRatio\",\n",
    "               \"outstandingLateAvgDays\",\n",
    "               \"writeOffTotalAmount\",\n",
    "               \"veryOverdueCount\",\n",
    "              ]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols = features,\n",
    "    outputCol =\"features\")\n",
    "assembled = assembler.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "659d83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paid_df1 = assembled.select(\"label\", \"features\").where(\"status != 'Outstanding'\")\n",
    "outstanding_df1 = assembled.select(\"invoice\", \"features\", assembled[\"featureLabel\"].alias(\"Actual_Late_Bucket\")).where(\"status = 'Outstanding'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc3f755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "\n",
    "(trainingData, testData) = paid_df1.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f64afac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1bbe236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", maxBins=400,numTrees=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e951ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06dac76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "985b4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save ML model\n",
    "model.save(\"/home/incorta/IncortaAnalytics/Tenants/ebsmldemo/data/ml_model/ARAgingPrediction1.ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06eea355",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2fb3958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6be92d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29e53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
